{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331f1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5044a231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They are considered to be a cult . There is no...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is not uncommon for people to have small bu...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the engine turns a stick that 's attached t...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It 's a push by a republican majority to gain ...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lean manufacturing is a production philosophy ...</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  They are considered to be a cult . There is no...  human\n",
       "1  It is not uncommon for people to have small bu...     ai\n",
       "2  So the engine turns a stick that 's attached t...  human\n",
       "3  It 's a push by a republican majority to gain ...  human\n",
       "4  Lean manufacturing is a production philosophy ...     ai"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "human    347\n",
       "ai       153\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading test dataset\n",
    "df = pd.read_csv(\"../data/hc3_sample_500.csv\")\n",
    "\n",
    "df = df[[\"text\", \"label\"]].dropna()\n",
    "display(df.head())\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b5aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 train samples\n",
      "100 test samples\n"
     ]
    }
   ],
   "source": [
    "# Creating train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"] # keeping class balance\n",
    ")\n",
    "\n",
    "print(len(X_train), \"train samples\")\n",
    "print(len(X_test), \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75587e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 5000) (100, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1,2),\n",
    "    stop_words=\"english\" # removing stopwords (the, and, is etc.) as these words appear so frequently across both classes they don't carry discriminative power\n",
    ")\n",
    "\n",
    "X_train_tdif = vectorizer.fit_transform(X_train)\n",
    "X_test_tdif = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_tdif.shape, X_test_tdif.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9521ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 thing</th>\n",
       "      <th>01100001</th>\n",
       "      <th>01100001 ascii</th>\n",
       "      <th>01100001 knows</th>\n",
       "      <th>02</th>\n",
       "      <th>02 account</th>\n",
       "      <th>092</th>\n",
       "      <th>092 98</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zones couple</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooming rink</th>\n",
       "      <th>zubir</th>\n",
       "      <th>zubir said</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerberg 6th</th>\n",
       "      <th>école</th>\n",
       "      <th>école polytechnique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000 thing  01100001  01100001 ascii  01100001 knows   02  02 account  \\\n",
       "0  0.0        0.0       0.0             0.0             0.0  0.0         0.0   \n",
       "1  0.0        0.0       0.0             0.0             0.0  0.0         0.0   \n",
       "2  0.0        0.0       0.0             0.0             0.0  0.0         0.0   \n",
       "3  0.0        0.0       0.0             0.0             0.0  0.0         0.0   \n",
       "4  0.0        0.0       0.0             0.0             0.0  0.0         0.0   \n",
       "\n",
       "   092  092 98   10  ...  zones  zones couple  zooming  zooming rink  zubir  \\\n",
       "0  0.0     0.0  0.0  ...    0.0           0.0      0.0           0.0    0.0   \n",
       "1  0.0     0.0  0.0  ...    0.0           0.0      0.0           0.0    0.0   \n",
       "2  0.0     0.0  0.0  ...    0.0           0.0      0.0           0.0    0.0   \n",
       "3  0.0     0.0  0.0  ...    0.0           0.0      0.0           0.0    0.0   \n",
       "4  0.0     0.0  0.0  ...    0.0           0.0      0.0           0.0    0.0   \n",
       "\n",
       "   zubir said  zuckerberg  zuckerberg 6th  école  école polytechnique  \n",
       "0         0.0         0.0             0.0    0.0                  0.0  \n",
       "1         0.0         0.0             0.0    0.0                  0.0  \n",
       "2         0.0         0.0             0.0    0.0                  0.0  \n",
       "3         0.0         0.0             0.0    0.0                  0.0  \n",
       "4         0.0         0.0             0.0    0.0                  0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names (the words/phrases that became columns)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert sparse matrix to a pandas DataFrame for exploration\n",
    "import pandas as pd\n",
    "tfidf_df = pd.DataFrame(X_train_tdif.toarray(), columns=feature_names)\n",
    "\n",
    "# Peek at the first few rows\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0243d0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like         7.521142\n",
       "people       6.755591\n",
       "different    5.503651\n",
       "just         5.441434\n",
       "time         5.385257\n",
       "make         5.321671\n",
       "use          5.282473\n",
       "used         4.894520\n",
       "does         4.611028\n",
       "way          4.581602\n",
       "url_0        4.272174\n",
       "think        4.083747\n",
       "water        3.917500\n",
       "need         3.916209\n",
       "really       3.774487\n",
       "help         3.724806\n",
       "things       3.647322\n",
       "know         3.538926\n",
       "work         3.456713\n",
       "air          3.435008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum TF-IDF values across all documents\n",
    "word_importance = tfidf_df.sum(axis=0).sort_values(ascending=False)\n",
    "word_importance.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a152c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in human text:\n",
      " like         6.219424\n",
      "just         4.927346\n",
      "people       4.355501\n",
      "url_0        4.272174\n",
      "time         4.190696\n",
      "does         3.996111\n",
      "really       3.675495\n",
      "think        3.567130\n",
      "know         3.150442\n",
      "need         3.003175\n",
      "use          3.000890\n",
      "things       2.997054\n",
      "way          2.958185\n",
      "different    2.948256\n",
      "make         2.947044\n",
      "water        2.857395\n",
      "actually     2.687690\n",
      "used         2.640587\n",
      "thing        2.635477\n",
      "lot          2.582788\n",
      "Name: human, dtype: float64\n",
      "\n",
      "Top words in AI text:\n",
      " help         3.267333\n",
      "different    2.555395\n",
      "people       2.400090\n",
      "make         2.374627\n",
      "use          2.281583\n",
      "used         2.253933\n",
      "important    1.953564\n",
      "data         1.929019\n",
      "financial    1.909913\n",
      "able         1.707342\n",
      "way          1.623417\n",
      "blood        1.547508\n",
      "including    1.526187\n",
      "energy       1.515292\n",
      "called       1.513787\n",
      "company      1.507037\n",
      "small        1.500514\n",
      "air          1.491941\n",
      "provide      1.413117\n",
      "helps        1.411010\n",
      "Name: ai, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Attaching labels to the tfidf DataFrame\n",
    "tfidf_labeled = tfidf_df.copy()\n",
    "tfidf_labeled[\"label\"] = y_train.reset_index(drop=True)\n",
    "\n",
    "# Summing TF-IDF values separately for human and ai\n",
    "word_importance_by_label = tfidf_labeled.groupby(\"label\").sum().T  # transpose so words are rows\n",
    "\n",
    "# Top words per class\n",
    "top_human = word_importance_by_label[\"human\"].sort_values(ascending=False).head(20)\n",
    "top_ai = word_importance_by_label[\"ai\"].sort_values(ascending=False).head(20)\n",
    "\n",
    "print(\"Top words in human text:\\n\", top_human)\n",
    "print(\"\\nTop words in AI text:\\n\", top_ai)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
